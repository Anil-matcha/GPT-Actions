{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOqDLH8yQa+Mx6/KRnx4NY0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anil-matcha/openai-functions/blob/main/Openai_functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "!pip install duckpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLF6nOi1Q70-",
        "outputId": "b5f55f6b-84cd-43f4-ae1d-a706422cc6b6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.27.8)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting duckpy\n",
            "  Downloading duckpy-3.2.0-py3-none-any.whl (5.0 kB)\n",
            "Requirement already satisfied: beautifulsoup4>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from duckpy) (4.11.2)\n",
            "Collecting httpx[http2]<0.19,>=0.14 (from duckpy)\n",
            "  Downloading httpx-0.18.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.9.1->duckpy) (2.4.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx[http2]<0.19,>=0.14->duckpy) (2022.12.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx[http2]<0.19,>=0.14->duckpy) (1.3.0)\n",
            "Collecting rfc3986[idna2008]<2,>=1.3 (from httpx[http2]<0.19,>=0.14->duckpy)\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting httpcore<0.14.0,>=0.13.3 (from httpx[http2]<0.19,>=0.14->duckpy)\n",
            "  Downloading httpcore-0.13.7-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h2==3.* (from httpx[http2]<0.19,>=0.14->duckpy)\n",
            "  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hyperframe<6,>=5.2.0 (from h2==3.*->httpx[http2]<0.19,>=0.14->duckpy)\n",
            "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting hpack<4,>=3.0 (from h2==3.*->httpx[http2]<0.19,>=0.14->duckpy)\n",
            "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
            "Collecting h11<0.13,>=0.11 (from httpcore<0.14.0,>=0.13.3->httpx[http2]<0.19,>=0.14->duckpy)\n",
            "  Downloading h11-0.12.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore<0.14.0,>=0.13.3->httpx[http2]<0.19,>=0.14->duckpy) (3.6.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio==3.*->httpcore<0.14.0,>=0.13.3->httpx[http2]<0.19,>=0.14->duckpy) (3.4)\n",
            "Installing collected packages: rfc3986, hyperframe, hpack, h2, h11, httpcore, httpx, duckpy\n",
            "Successfully installed duckpy-3.2.0 h11-0.12.0 h2-3.2.0 hpack-3.0.0 httpcore-0.13.7 httpx-0.18.2 hyperframe-5.2.0 rfc3986-1.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wneNPjH1QhdF",
        "outputId": "5df3ec52-acd3-4892-fd39-7cfb2455b5fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Message {'input': 'IPL 2023 winner'} <class 'dict'>\n",
            "{\n",
            "  \"id\": \"chatcmpl-7RM8RxJRnl3k4fOTBN9RWO7521S6h\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"created\": 1686754299,\n",
            "  \"model\": \"gpt-3.5-turbo-0613\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"role\": \"assistant\",\n",
            "        \"content\": \"The winner of the IPL 2023 was the Chennai Super Kings (CSK). They defeated the Gujarat Titans (GT) to claim their fifth IPL title.\"\n",
            "      },\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 3412,\n",
            "    \"completion_tokens\": 32,\n",
            "    \"total_tokens\": 3444\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "import json\n",
        "from duckpy import Client\n",
        "import ast\n",
        "\n",
        "duckduckgo_client = Client()\n",
        "\n",
        "openai.api_key = \"api-key\"\n",
        "\n",
        "def search_api(input):\n",
        "    output = duckduckgo_client.search(input)\n",
        "    return str(output)\n",
        "\n",
        "def run_conversation():\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo-0613\",\n",
        "        messages=[{\"role\": \"user\", \"content\": \"Tell me IPL 2023 winner?\"}],\n",
        "        functions=[\n",
        "            {\n",
        "                \"name\": \"search_api\",\n",
        "                \"description\": \"Used to search online\",\n",
        "                \"parameters\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"input\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"description\": \"Input query\",\n",
        "                        },\n",
        "                    },\n",
        "                    \"required\": [\"input\"],\n",
        "                },\n",
        "            }\n",
        "        ],\n",
        "        function_call=\"auto\",\n",
        "    )\n",
        "\n",
        "    message = response[\"choices\"][0][\"message\"]\n",
        "\n",
        "    # Step 2, check if the model wants to call a function\n",
        "    if message.get(\"function_call\"):\n",
        "        function_name = message[\"function_call\"][\"name\"]\n",
        "        args = ast.literal_eval(message[\"function_call\"][\"arguments\"])\n",
        "        print(\"Message\", args, type(args))\n",
        "        # Step 3, call the function\n",
        "        # Note: the JSON response from the model may not be valid JSON\n",
        "        function_response = search_api(\n",
        "            input=args.get(\"input\"),\n",
        "        )\n",
        "\n",
        "        # Step 4, send model the info on the function call and function response\n",
        "        second_response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo-0613\",\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": \"Tell me IPL 2023 winner?\"},\n",
        "                message,\n",
        "                {\n",
        "                    \"role\": \"function\",\n",
        "                    \"name\": function_name,\n",
        "                    \"content\": function_response,\n",
        "                },\n",
        "            ],\n",
        "        )\n",
        "        return second_response\n",
        "\n",
        "print(run_conversation())"
      ]
    }
  ]
}